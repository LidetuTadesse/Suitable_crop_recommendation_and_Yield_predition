{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bac066",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f4eacd",
   "metadata": {},
   "source": [
    "## Initialize Data Populator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c6dcc",
   "metadata": {},
   "source": [
    "## Load Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba6d9b1",
   "metadata": {},
   "source": [
    "## Generate Populated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48478a47",
   "metadata": {},
   "source": [
    "## Basic Statistics and Generation Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eec25c",
   "metadata": {},
   "source": [
    "## Enhanced Comparison Plotting Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa4483",
   "metadata": {},
   "source": [
    "## Analyze Key Agricultural Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed76305",
   "metadata": {},
   "source": [
    "## Comprehensive Crop Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bf2a92",
   "metadata": {},
   "source": [
    "## Correlation and Relationship Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594c548",
   "metadata": {},
   "source": [
    "## Environmental Factor Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459ef2dd",
   "metadata": {},
   "source": [
    "## Nutrient Analysis (N, P, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afcb730",
   "metadata": {},
   "source": [
    "## save Populated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da67580f",
   "metadata": {},
   "source": [
    "## Comprehensive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3afcac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Import Required Libraries\n",
    "# ==========================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Add Scripts folder to path\n",
    "sys.path.append(os.path.abspath(\"../Scripts\"))\n",
    "\n",
    "from data_populator import RangeDataPopulator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e76fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original dataset\n",
    "df = pd.read_csv(\"../data/processed/crop_clean.csv\", dtype=str)\n",
    "print(\"Original rows: \", len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f3cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Initialize Populator\n",
    "# ==========================================================\n",
    "\n",
    "n_samples_per_row = 100\n",
    "decimal_precision = 3\n",
    "\n",
    "populator = RangeDataPopulator(\n",
    "    n_samples=n_samples_per_row,\n",
    "    decimal_places=decimal_precision\n",
    ")\n",
    "\n",
    "populated_df = populator.populate(df)\n",
    "\n",
    "print(\"Original rows:\", len(df))\n",
    "print(\"Populated rows:\", len(populated_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207ec236",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Original rows:\", len(df))\n",
    "print(\"Populated rows:\", len(populated_df))\n",
    "\n",
    "populated_df.info()\n",
    "populated_df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "637fd545",
   "metadata": {},
   "outputs": [],
   "source": [
    "populated_df.to_csv(\"../data/processed/cereal_populated_data.csv\",index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9929791f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "226bf8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22bbcec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data path\n",
    "DATA_PATH = \"../data/processed/cereal_populated_data.csv\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Preview\n",
    "df.head()\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c40c42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns (environmental factors)\n",
    "FEATURES = [\n",
    "    \"N (kg/ha)\", \"P (kg/ha)\", \"K (kg/ha)\",\n",
    "    \"T (°C)\", \"PH\",\n",
    "    \"RF (mm)\", \"LGP\",\n",
    "    \"Altitude (m)\", \"Crop Type\"\n",
    "]\n",
    "\n",
    "# Target\n",
    "TARGET = \"Crop Species\"\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET]\n",
    "\n",
    "# Encode Crop Type inside X\n",
    "X = pd.get_dummies(X, columns=[\"Crop Type\"])\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0813cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode crop type labels\n",
    "label_encoder_crop = LabelEncoder()\n",
    "y_encoded = label_encoder_crop.fit_transform(y)\n",
    "\n",
    "# Mapping for interpretation\n",
    "crop_type_mapping = dict(\n",
    "    zip(label_encoder_crop.classes_, label_encoder_crop.transform(label_encoder_crop.classes_))\n",
    ")\n",
    "\n",
    "crop_type_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f1fbaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96b2d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ede50fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_type_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "crop_type_model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28f3d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = crop_type_model.predict(X_test_scaled)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=label_encoder_crop.classes_\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a99a0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=label_encoder_crop.classes_,\n",
    "    yticklabels=label_encoder_crop.classes_\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix – Crop Type Prediction\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f59c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f8121a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2. LOAD DATA\n",
    "# ============================================\n",
    "\n",
    "data_path = \"../data/processed/cereal_populated_data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "288a57d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3. DEFINE FEATURES & TARGET\n",
    "# ============================================\n",
    "\n",
    "features = [\n",
    "    \"N (kg/ha)\",\n",
    "    \"P (kg/ha)\",\n",
    "    \"K (kg/ha)\",\n",
    "    \"T (°C)\",\n",
    "    \"PH\",\n",
    "    \"RF (mm)\",\n",
    "    \"LGP\",\n",
    "    \"Altitude (m)\",\n",
    "    \"Crop Type\"\n",
    "]\n",
    "\n",
    "target = \"Crop Species\"\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eb1626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4. ENCODE TARGET\n",
    "# ============================================\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "class_names = label_encoder.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2882f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5. STRATIFIED TRAIN-TEST SPLIT\n",
    "# ============================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y_encoded,\n",
    "    test_size=0.2,\n",
    "    stratify=y_encoded,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05e51382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 6. PREPROCESSING PIPELINE\n",
    "# ============================================\n",
    "\n",
    "numeric_features = [\n",
    "    \"N (kg/ha)\",\n",
    "    \"P (kg/ha)\",\n",
    "    \"K (kg/ha)\",\n",
    "    \"T (°C)\",\n",
    "    \"PH\",\n",
    "    \"RF (mm)\",\n",
    "    \"LGP\",\n",
    "    \"Altitude (m)\"\n",
    "]\n",
    "\n",
    "categorical_features = [\"Crop Type\"]\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65bfdc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 7. EVALUATION FUNCTION\n",
    "# ============================================\n",
    "\n",
    "def evaluate_model(model_name, pipeline, X_train, X_test, y_train, y_test, results_dict):\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n===== {model_name} =====\")\n",
    "    print(f\"Accuracy      : {acc:.4f}\")\n",
    "    print(f\"Macro F1      : {f1_macro:.4f}\")\n",
    "    print(f\"Weighted F1   : {f1_weighted:.4f}\")\n",
    "    \n",
    "    # plt.figure(figsize=(8,6))\n",
    "    # sns.heatmap(cm, annot=False, cmap=\"Blues\")\n",
    "    # plt.title(f\"{model_name} - Confusion Matrix\")\n",
    "    # plt.xlabel(\"Predicted\")\n",
    "    # plt.ylabel(\"Actual\")\n",
    "    # plt.show()\n",
    "    \n",
    "    results_dict[model_name] = {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Macro F1\": f1_macro,\n",
    "        \"Weighted F1\": f1_weighted\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e22000ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 8. LOGISTIC REGRESSION\n",
    "# ============================================\n",
    "\n",
    "results = {}\n",
    "\n",
    "log_reg_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "evaluate_model(\"Logistic Regression\", log_reg_pipeline,\n",
    "               X_train, X_test, y_train, y_test, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4554cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 9. SUPPORT VECTOR MACHINE\n",
    "# ============================================\n",
    "\n",
    "svm_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", SVC(kernel=\"rbf\", random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "evaluate_model(\"SVM\", svm_pipeline,\n",
    "               X_train, X_test, y_train, y_test, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01565d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 10. RANDOM FOREST\n",
    "# ============================================\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "evaluate_model(\"Random Forest\", rf_pipeline,\n",
    "               X_train, X_test, y_train, y_test, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "599309f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 11. XGBOOST\n",
    "# ============================================\n",
    "\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "evaluate_model(\"XGBoost\", xgb_pipeline,\n",
    "               X_train, X_test, y_train, y_test, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "296e4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 12. LIGHTGBM\n",
    "# ============================================\n",
    "\n",
    "lgb_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LGBMClassifier(\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "evaluate_model(\"LightGBM\", lgb_pipeline,\n",
    "               X_train, X_test, y_train, y_test, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5568fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 13. MODEL COMPARISON TABLE\n",
    "# ============================================\n",
    "\n",
    "comparison_df = pd.DataFrame(results).T.sort_values(by=\"Accuracy\", ascending=False)\n",
    "\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16a94390",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('results_dict:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c30edfc",
   "metadata": {},
   "source": [
    "## Yield prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1a1f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1. DEFINE FEATURES & TARGET (REGRESSION)\n",
    "# ============================================\n",
    "\n",
    "features = [\n",
    "    \"N (kg/ha)\",\n",
    "    \"P (kg/ha)\",\n",
    "    \"K (kg/ha)\",\n",
    "    \"T (°C)\",\n",
    "    \"PH\",\n",
    "    \"RF (mm)\",\n",
    "    \"LGP\",\n",
    "    \"Altitude (m)\",\n",
    "    \"Crop Type\",\n",
    "    \"Crop Species\"\n",
    "]\n",
    "\n",
    "target = \"Yield (q/ha)\"\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a1bca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2. TRAIN-TEST SPLIT\n",
    "# ============================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb18351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3. PREPROCESSING PIPELINE\n",
    "# ============================================\n",
    "\n",
    "numeric_features = [\n",
    "    \"N (kg/ha)\",\n",
    "    \"P (kg/ha)\",\n",
    "    \"K (kg/ha)\",\n",
    "    \"T (°C)\",\n",
    "    \"PH\",\n",
    "    \"RF (mm)\",\n",
    "    \"LGP\",\n",
    "    \"Altitude (m)\"\n",
    "]\n",
    "\n",
    "categorical_features = [\"Crop Type\", \"Crop Species\"]\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7f79bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4. REGRESSION EVALUATION FUNCTION\n",
    "# ============================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_regression_model(model_name, pipeline, X_train, X_test, y_train, y_test, results_dict):\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n===== {model_name} =====\")\n",
    "    print(f\"MAE  : {mae:.4f}\")\n",
    "    print(f\"RMSE : {rmse:.4f}\")\n",
    "    print(f\"R²   : {r2:.4f}\")\n",
    "    \n",
    "    results_dict[model_name] = {\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eba19123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5. LINEAR REGRESSION\n",
    "# ============================================\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "results_reg = {}\n",
    "\n",
    "linreg_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", LinearRegression())\n",
    "])\n",
    "\n",
    "evaluate_regression_model(\"Linear Regression\",\n",
    "                          linreg_pipeline,\n",
    "                          X_train, X_test,\n",
    "                          y_train, y_test,\n",
    "                          results_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d09e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 6. SUPPORT VECTOR REGRESSION\n",
    "# ============================================\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", SVR(kernel=\"rbf\"))\n",
    "])\n",
    "\n",
    "evaluate_regression_model(\"SVR\",\n",
    "                          svr_pipeline,\n",
    "                          X_train, X_test,\n",
    "                          y_train, y_test,\n",
    "                          results_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbcc19fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 7. RANDOM FOREST REGRESSOR\n",
    "# ============================================\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "evaluate_regression_model(\"Random Forest Regressor\",\n",
    "                          rf_reg_pipeline,\n",
    "                          X_train, X_test,\n",
    "                          y_train, y_test,\n",
    "                          results_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acd1f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 8. XGBOOST REGRESSOR\n",
    "# ============================================\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_reg_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", XGBRegressor(\n",
    "        random_state=RANDOM_STATE,\n",
    "        objective=\"reg:squarederror\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "evaluate_regression_model(\"XGBoost Regressor\",\n",
    "                          xgb_reg_pipeline,\n",
    "                          X_train, X_test,\n",
    "                          y_train, y_test,\n",
    "                          results_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24af8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 9. LIGHTGBM REGRESSOR\n",
    "# ============================================\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgb_reg_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", LGBMRegressor(\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "evaluate_regression_model(\"LightGBM Regressor\",\n",
    "                          lgb_reg_pipeline,\n",
    "                          X_train, X_test,\n",
    "                          y_train, y_test,\n",
    "                          results_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6522412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create KNN Regressor pipeline\n",
    "knn_reg_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", KNeighborsRegressor(\n",
    "        n_neighbors=5  # you can adjust this\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Evaluate using your regression function\n",
    "evaluate_regression_model(\"KNN Regressor\",\n",
    "                          knn_reg_pipeline,\n",
    "                          X_train, X_test,\n",
    "                          y_train, y_test,\n",
    "                          results_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 10. REGRESSION MODEL COMPARISON\n",
    "# ============================================\n",
    "\n",
    "comparison_reg_df = pd.DataFrame(results_reg).T.sort_values(by=\"R2\", ascending=False)\n",
    "\n",
    "comparison_reg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77fdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
